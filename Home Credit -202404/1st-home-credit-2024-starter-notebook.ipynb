{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Example Notebook\n\nWelcome to the example notebook for the Home Credit Kaggle competition. The goal of this competition is to determine how likely a customer is going to default on an issued loan. The main difference between the [first](https://www.kaggle.com/c/home-credit-default-risk) and this competition is that now your submission will be scored with a custom metric that will take into account how well the model performs in future. A decline in performance will be penalized. The goal is to create a model that is stable and performs well in the future.\n\nIn this notebook you will see how to:\n* Load the data\n* Join tables with Polars - a DataFrame library implemented in Rust language, designed to be blazingy fast and memory efficient.  \n* Create simple aggregation features\n* Train a LightGBM model\n* Create a submission table\n\n## Load the data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score \n\ndataPath = \"/kaggle/input/home-credit-credit-risk-model-stability/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:14:38.568665Z","iopub.execute_input":"2024-05-13T13:14:38.569584Z","iopub.status.idle":"2024-05-13T13:14:42.579225Z","shell.execute_reply.started":"2024-05-13T13:14:38.569525Z","shell.execute_reply":"2024-05-13T13:14:42.578052Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n    # implement here all desired dtypes for tables\n    # the following is just an example\n    for col in df.columns:\n        # last letter of column name will help you determine the type\n        if col[-1] in (\"P\", \"A\"):\n            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n\n    return df\n\ndef convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n    for col in df.columns:  \n        if df[col].dtype.name in ['object', 'string']:\n            df[col] = df[col].astype(\"string\").astype('category')\n            current_categories = df[col].cat.categories\n            new_categories = current_categories.to_list() + [\"Unknown\"]\n            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n            df[col] = df[col].astype(new_dtype)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:14:42.581294Z","iopub.execute_input":"2024-05-13T13:14:42.581746Z","iopub.status.idle":"2024-05-13T13:14:42.595342Z","shell.execute_reply.started":"2024-05-13T13:14:42.581709Z","shell.execute_reply":"2024-05-13T13:14:42.592700Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_basetable = pl.read_csv(dataPath + \"csv_files/train/train_base.csv\")\ntrain_static = pl.concat(\n    [\n        pl.read_csv(dataPath + \"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes),\n    ],\n    how=\"vertical_relaxed\",\n)\ntrain_static_cb = pl.read_csv(dataPath + \"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\ntrain_person_1 = pl.read_csv(dataPath + \"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes) \ntrain_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) ","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:14:42.597511Z","iopub.execute_input":"2024-05-13T13:14:42.598693Z","iopub.status.idle":"2024-05-13T13:14:59.834362Z","shell.execute_reply.started":"2024-05-13T13:14:42.598646Z","shell.execute_reply":"2024-05-13T13:14:59.833444Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_basetable = pl.read_csv(dataPath + \"csv_files/test/test_base.csv\")\ntest_static = pl.concat(\n    [\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_0.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_1.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes),\n    ],\n    how=\"vertical_relaxed\",\n)\ntest_static_cb = pl.read_csv(dataPath + \"csv_files/test/test_static_cb_0.csv\").pipe(set_table_dtypes)\ntest_person_1 = pl.read_csv(dataPath + \"csv_files/test/test_person_1.csv\").pipe(set_table_dtypes) \ntest_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) ","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:14:59.837396Z","iopub.execute_input":"2024-05-13T13:14:59.838305Z","iopub.status.idle":"2024-05-13T13:14:59.897849Z","shell.execute_reply.started":"2024-05-13T13:14:59.838257Z","shell.execute_reply":"2024-05-13T13:14:59.896473Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering\n\nIn this part, we can see a simple example of joining tables via `case_id`. Here the loading and joining is done with polars library. Polars library is blazingly fast and has much smaller memory footprint than pandas. ","metadata":{}},{"cell_type":"code","source":"# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or \n# also num_group2 column.\ntrain_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n)\n\n# Here num_group1=0 has special meaning, it is the person who applied for the loan.\ntrain_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n    pl.col(\"num_group1\") == 0\n).drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n\n# Here we have num_goup1 and num_group2, so we need to aggregate again.\ntrain_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n)\n\n# We will process in this examples only A-type and M-type columns, so we need to select them.\nselected_static_cols = []\nfor col in train_static.columns:\n    if col[-1] in (\"A\", \"M\"):\n        selected_static_cols.append(col)\nprint(selected_static_cols)\n\nselected_static_cb_cols = []\nfor col in train_static_cb.columns:\n    if col[-1] in (\"A\", \"M\"):\n        selected_static_cb_cols.append(col)\nprint(selected_static_cb_cols)\n\n# Join all tables together.\ndata = train_basetable.join(\n    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n).join(\n    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n).join(\n    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n).join(\n    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n).join(\n    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n)\n\ndel train_basetable\ndel train_static_cb\ndel train_person_1_feats_2\ndel train_credit_bureau_b_2_feats\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:14:59.899482Z","iopub.execute_input":"2024-05-13T13:14:59.899848Z","iopub.status.idle":"2024-05-13T13:15:01.750073Z","shell.execute_reply.started":"2024-05-13T13:14:59.899816Z","shell.execute_reply":"2024-05-13T13:15:01.748927Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A']\n['description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n)\n\ntest_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n    pl.col(\"num_group1\") == 0\n).drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n\ntest_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n)\n\ndata_submission = test_basetable.join(\n    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n).join(\n    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n).join(\n    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n).join(\n    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n).join(\n    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:01.751922Z","iopub.execute_input":"2024-05-13T13:15:01.752398Z","iopub.status.idle":"2024-05-13T13:15:01.771061Z","shell.execute_reply.started":"2024-05-13T13:15:01.752356Z","shell.execute_reply":"2024-05-13T13:15:01.769876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"case_ids = data[\"case_id\"].unique().shuffle(seed=1)\ncase_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\ncase_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n\ncols_pred = []\nfor col in data.columns:\n    if col[-1].isupper() and col[:-1].islower():\n        cols_pred.append(col)\n\nprint(cols_pred)\n\ndef from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n    return (\n        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n    )\n\nbase_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\nbase_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\nbase_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n\nfor df in [X_train, X_valid, X_test]:\n    df = convert_strings(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:01.772627Z","iopub.execute_input":"2024-05-13T13:15:01.773179Z","iopub.status.idle":"2024-05-13T13:15:10.902070Z","shell.execute_reply.started":"2024-05-13T13:15:01.773136Z","shell.execute_reply":"2024-05-13T13:15:10.900848Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Train: {X_train.shape}\")\nprint(f\"Valid: {X_valid.shape}\")\nprint(f\"Test: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:10.903500Z","iopub.execute_input":"2024-05-13T13:15:10.904424Z","iopub.status.idle":"2024-05-13T13:15:10.910499Z","shell.execute_reply.started":"2024-05-13T13:15:10.904389Z","shell.execute_reply":"2024-05-13T13:15:10.909147Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train: (915995, 48)\nValid: (305332, 48)\nTest: (305332, 48)\n","output_type":"stream"}]},{"cell_type":"code","source":"cols = X_train.loc[:, X_train.iloc[0].map(type) == str].columns.unique()\ncols","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:24.365656Z","iopub.execute_input":"2024-05-13T13:15:24.366127Z","iopub.status.idle":"2024-05-13T13:15:24.385047Z","shell.execute_reply.started":"2024-05-13T13:15:24.366091Z","shell.execute_reply":"2024-05-13T13:15:24.383505Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M',\n       'lastcancelreason_561M', 'lastrejectcommoditycat_161M',\n       'lastrejectcommodtypec_5251769M', 'lastrejectreason_759M',\n       'lastrejectreasonclient_4145040M', 'previouscontdistrict_112M'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"X_train = X_train.fillna(X_train.mode().iloc[0])\nX_valid = X_valid.fillna(X_train.mode().iloc[0])\nX_test = X_test.fillna(X_train.mode().iloc[0])\n\nC_X_train = X_train.copy()\nC_X_valid = X_valid.copy()\nC_X_test = X_test.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:36.043269Z","iopub.execute_input":"2024-05-13T13:15:36.043699Z","iopub.status.idle":"2024-05-13T13:15:41.092872Z","shell.execute_reply.started":"2024-05-13T13:15:36.043662Z","shell.execute_reply":"2024-05-13T13:15:41.091738Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for col in cols:\n    cat_list = {*X_train[col], *X_valid[col], *X_test[col]}\n    X_train[col] = X_train[col].astype(pd.CategoricalDtype(cat_list))\n    X_valid[col] = X_valid[col].astype(pd.CategoricalDtype(cat_list))\n    X_test[col] = X_test[col].astype(pd.CategoricalDtype(cat_list))\n\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:41.094917Z","iopub.execute_input":"2024-05-13T13:15:41.095237Z","iopub.status.idle":"2024-05-13T13:15:51.739958Z","shell.execute_reply.started":"2024-05-13T13:15:41.095208Z","shell.execute_reply":"2024-05-13T13:15:51.738746Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f\"Train: {X_train.shape}\")\nprint(f\"Valid: {X_valid.shape}\")\nprint(f\"Test: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:56.397586Z","iopub.execute_input":"2024-05-13T13:15:56.398017Z","iopub.status.idle":"2024-05-13T13:15:56.406981Z","shell.execute_reply.started":"2024-05-13T13:15:56.397976Z","shell.execute_reply":"2024-05-13T13:15:56.405697Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Train: (915995, 884)\nValid: (305332, 884)\nTest: (305332, 884)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Hottie = OneHotEncoder()\n# let's define the column we want to convert\nfeatures_cat = ['Comapnay','model']\ntransformer = ColumnTransformer([('One_hottie',Hottie,features_cat)],\n                            remainder = 'passthrough')\ntransformed_X = transformer.fit_transform(X)\nTransformed_X = pd.DataFrame(transformed_X)","metadata":{}},{"cell_type":"markdown","source":"## Training LightGBM\n\nMinimal example of LightGBM training is shown below.","metadata":{}},{"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\n\nparams = {\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"max_depth\": 3,\n    \"num_leaves\": 32,\n    \"learning_rate\": 0.04,#0.05\n    \"feature_fraction\": 0.9,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"n_estimators\": 500,\n    \"verbose\": -1,\n}\nresults = {}\ngbm = lgb.train(\n    params,\n    lgb_train,\n    valid_sets=lgb_valid,\n#     num_boost_round = 1000,\n#     callbacks=[lgb.log_evaluation(50), lgb.early_stopping(20), lgb.record_evaluation(results)]\n    callbacks=[lgb.log_evaluation(25), lgb.early_stopping(10)]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation with AUC and then comparison with the stability metric is shown below.","metadata":{}},{"cell_type":"markdown","source":"import matplotlib.pyplot as plt\nplt.plot(results['X_train']['auc'], label='train')\nplt.plot(results['X_valid']['auc'], label='valid')\nplt.ylabel('Log loss')\nplt.xlabel('Boosting round')\nplt.title('Training performance')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:55:25.752383Z","iopub.execute_input":"2024-04-14T13:55:25.752804Z","iopub.status.idle":"2024-04-14T13:55:25.794958Z","shell.execute_reply.started":"2024-04-14T13:55:25.752770Z","shell.execute_reply":"2024-04-14T13:55:25.793338Z"}}},{"cell_type":"code","source":"for base, X in [(base_train, X_train), (base_valid, X_valid), (base_test, X_test)]:\n    y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n    base[\"score\"] = y_pred\n\nprint(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}') \nprint(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], base_valid[\"score\"])}') \nprint(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n        .sort_values(\"WEEK_NUM\")\\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n    \n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a*x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.mean(gini_in_time)\n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n\nstability_score_train = gini_stability(base_train)\nstability_score_valid = gini_stability(base_valid)\nstability_score_test = gini_stability(base_test)\n\nprint(f'The stability score on the train set is: {stability_score_train}') \nprint(f'The stability score on the valid set is: {stability_score_valid}') \nprint(f'The stability score on the test set is: {stability_score_test}')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n\nScoring the submission dataset is below, we need to take care of new categories. Then we save the score as a last step. ","metadata":{}},{"cell_type":"code","source":"X_submission = data_submission[cols_pred].to_pandas()\nX_submission = convert_strings(X_submission)\nX_submission = X_submission.fillna(X_train.mode().iloc[0])\nfor col in cols:\n    cat_list = {*C_X_train[col], *C_X_valid[col], *C_X_test[col]}\n    X_submission[col] = X_submission[col].astype(pd.CategoricalDtype(cat_list))\n\ndel C_X_train\ndel C_X_valid\ndel C_X_test\ngc.collect()\n    \nX_submission = pd.get_dummies(X_submission)\ndiff = list(set(X_submission.columns) ^ set(X_train.columns))\nX_submission.loc[:,diff] = False\ncolumns = X_train.columns\nX_submission = X_submission.reindex(columns=columns)\n\ndel X_train\ndel X_valid\ndel X_test\ngc.collect()\n\ny_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X_submission = data_submission[cols_pred].to_pandas()\nX_submission = convert_strings(X_submission)\ncategorical_cols = X_train.select_dtypes(include=['category']).columns\n\nfor col in categorical_cols:\n    train_categories = set(X_train[col].cat.categories)\n    submission_categories = set(X_submission[col].cat.categories)\n    new_categories = submission_categories - train_categories\n    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n    X_train[col] = X_train[col].astype(new_dtype)\n    X_submission[col] = X_submission[col].astype(new_dtype)\n\ny_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:49:24.515997Z","iopub.execute_input":"2024-04-15T12:49:24.517088Z","iopub.status.idle":"2024-04-15T12:49:25.464643Z","shell.execute_reply.started":"2024-04-15T12:49:24.517045Z","shell.execute_reply":"2024-04-15T12:49:25.462361Z"}}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n    \"score\": y_submission_pred\n}).set_index('case_id')\nsubmission.to_csv(\"./submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best of luck, and most importantly, enjoy the process of learning and discovery! \n\n<img src=\"https://i.imgur.com/obVWIBh.png\" alt=\"Image\" width=\"700\"/>","metadata":{}}]}